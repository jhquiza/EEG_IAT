{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PowerTransformer, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from mango import Tuner, scheduler\n",
    "from scipy.stats import uniform\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 88 entries, 21100 to 24101\n",
      "Data columns (total 26 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   max_degree_b1d         88 non-null     int64  \n",
      " 1   max_degree_b2c         88 non-null     int64  \n",
      " 2   max_degree_b2i         88 non-null     int64  \n",
      " 3   max_degree_gi          88 non-null     int64  \n",
      " 4   mean_eccentricity_ac   88 non-null     float64\n",
      " 5   mean_eccentricity_b2i  88 non-null     float64\n",
      " 6   mean_eccentricity_b2d  88 non-null     float64\n",
      " 7   mean_eccentricity_gc   88 non-null     float64\n",
      " 8   mean_eccentricity_gd   88 non-null     float64\n",
      " 9   EX2_score              88 non-null     int64  \n",
      " 10  school_years           88 non-null     int64  \n",
      " 11  IRI_PT                 88 non-null     float64\n",
      " 12  IRI_EC                 88 non-null     float64\n",
      " 13  RPQ AP                 88 non-null     float64\n",
      " 14  TD                     88 non-null     float64\n",
      " 15  AN                     88 non-null     float64\n",
      " 16  AL                     88 non-null     float64\n",
      " 17  mean_eccentricity_ti   88 non-null     float64\n",
      " 18  IRI_PD                 88 non-null     float64\n",
      " 19  RPQ AR                 88 non-null     float64\n",
      " 20  exposure_level_high    88 non-null     uint8  \n",
      " 21  exposure_level_low     88 non-null     uint8  \n",
      " 22  gender_F               88 non-null     uint8  \n",
      " 23  gender_M               88 non-null     uint8  \n",
      " 24  victims_self_no        88 non-null     uint8  \n",
      " 25  victims_self_yes       88 non-null     uint8  \n",
      "dtypes: float64(14), int64(6), uint8(6)\n",
      "memory usage: 15.0 KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('medidas_conectividad_globales_comportamentales_demograficos_2.csv')\n",
    "data.set_index('subject', inplace=True)\n",
    "# variables más importantes según modelos de clasificación\n",
    "data = data[['max_degree_b1d', 'max_degree_b2c', 'max_degree_b2i', 'max_degree_gi', 'mean_eccentricity_ac', 'mean_eccentricity_b2i', 'mean_eccentricity_b2d', 'mean_eccentricity_gc', 'mean_eccentricity_gd', 'exposure_level', 'EX2_score', 'school_years', 'gender', 'IRI_PT', 'IRI_EC', 'RPQ AP', 'TD', 'AN', 'AL', 'mean_eccentricity_ti', 'IRI_PD', 'RPQ AR', 'victims_self']]\n",
    "# eliminación de sujetos con datos incompletos\n",
    "data.dropna(inplace=True)\n",
    "df = data.copy()\n",
    "# codificación de variables categóricas\n",
    "data = pd.get_dummies(data)\n",
    "data.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# normalización de datos con standard escaler\n",
    "continuas_cols = data.select_dtypes(include=['float64']).columns.to_list()\n",
    "discretas_cols = data.select_dtypes(include=['int64']).columns.to_list()\n",
    "preprocessor_sc = ColumnTransformer([('scaler', StandardScaler(), continuas_cols), ('min_max', MinMaxScaler(), discretas_cols)], remainder='passthrough')\n",
    "data_sc = preprocessor_sc.fit_transform(data)\n",
    "# normalización de datos con power transformer\n",
    "preprocessor_pt = ColumnTransformer([('pt', PowerTransformer(), continuas_cols), ('min_max', MinMaxScaler(), discretas_cols)], remainder='passthrough')\n",
    "data_pt = preprocessor_pt.fit_transform(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def clusters_kmeans(data, max_clusters=10):\n",
    "    inertias = []\n",
    "    sil_scores = []\n",
    "    cal_scores = []\n",
    "    dav_scores = []\n",
    "    for i in range(2,max_clusters+1):\n",
    "        kmeans = KMeans(i, random_state=72).fit(data)\n",
    "        inertia = kmeans.inertia_\n",
    "        inertias.append(inertia)\n",
    "        labels = kmeans.labels_\n",
    "        sil = silhouette_score(X=data, labels=labels)\n",
    "        sil_scores.append(sil)\n",
    "        cal = calinski_harabasz_score(X=data, labels=labels)\n",
    "        cal_scores.append(cal)\n",
    "        dav = davies_bouldin_score(X=data, labels=labels)\n",
    "        dav_scores.append(dav)\n",
    "    return inertias, sil_scores, cal_scores, dav_scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "   silhouette kmeans np  calinski kmeans np  davies kmeans np  \\\n2              0.140430           15.948231          2.258104   \n3              0.141865           13.543720          1.953296   \n4              0.104275           11.728366          2.177642   \n5              0.098943           10.313543          2.024446   \n6              0.103143            9.694866          1.749558   \n\n   silhouette kmeans sc  calinski kmeans sc  davies kmeans sc  \\\n2              0.115895           10.520811          2.745652   \n3              0.096446           10.074285          2.429310   \n4              0.096957            8.989544          2.212793   \n5              0.088588            8.588638          2.195654   \n6              0.101929            8.109551          1.998565   \n\n   silhouette kmeans pt  calinski kmeans pt  davies kmeans pt  \n2              0.103173           11.578432          2.689949  \n3              0.102325           10.640033          2.487609  \n4              0.088649            9.166728          2.556416  \n5              0.091740            8.539001          2.232042  \n6              0.084863            7.459235          2.188218  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>silhouette kmeans np</th>\n      <th>calinski kmeans np</th>\n      <th>davies kmeans np</th>\n      <th>silhouette kmeans sc</th>\n      <th>calinski kmeans sc</th>\n      <th>davies kmeans sc</th>\n      <th>silhouette kmeans pt</th>\n      <th>calinski kmeans pt</th>\n      <th>davies kmeans pt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>0.140430</td>\n      <td>15.948231</td>\n      <td>2.258104</td>\n      <td>0.115895</td>\n      <td>10.520811</td>\n      <td>2.745652</td>\n      <td>0.103173</td>\n      <td>11.578432</td>\n      <td>2.689949</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.141865</td>\n      <td>13.543720</td>\n      <td>1.953296</td>\n      <td>0.096446</td>\n      <td>10.074285</td>\n      <td>2.429310</td>\n      <td>0.102325</td>\n      <td>10.640033</td>\n      <td>2.487609</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.104275</td>\n      <td>11.728366</td>\n      <td>2.177642</td>\n      <td>0.096957</td>\n      <td>8.989544</td>\n      <td>2.212793</td>\n      <td>0.088649</td>\n      <td>9.166728</td>\n      <td>2.556416</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.098943</td>\n      <td>10.313543</td>\n      <td>2.024446</td>\n      <td>0.088588</td>\n      <td>8.588638</td>\n      <td>2.195654</td>\n      <td>0.091740</td>\n      <td>8.539001</td>\n      <td>2.232042</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.103143</td>\n      <td>9.694866</td>\n      <td>1.749558</td>\n      <td>0.101929</td>\n      <td>8.109551</td>\n      <td>1.998565</td>\n      <td>0.084863</td>\n      <td>7.459235</td>\n      <td>2.188218</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clústeres por KMeans, datos sin normalizar\n",
    "inertias_np, sil_scores_np, cal_scores_np, dav_scores_np = clusters_kmeans(data=data)\n",
    "# clústeres por KMeans, Standard Scaler\n",
    "inertias_sc, sil_scores_sc, cal_scores_sc, dav_scores_sc = clusters_kmeans(data=data_sc)\n",
    "# clústeres por KMeans, PowerTransformer\n",
    "inertias_pt, sil_scores_pt, cal_scores_pt, dav_scores_pt = clusters_kmeans(data=data_pt)\n",
    "# Dataframe con métricas de clustering de KMeans\n",
    "df_kmeans = pd.DataFrame(data=[sil_scores_np, cal_scores_np, dav_scores_np, sil_scores_sc, cal_scores_sc, dav_scores_sc, sil_scores_pt, cal_scores_pt, dav_scores_pt], index=['silhouette kmeans np', 'calinski kmeans np', 'davies kmeans np', 'silhouette kmeans sc', 'calinski kmeans sc', 'davies kmeans sc', 'silhouette kmeans pt', 'calinski kmeans pt', 'davies kmeans pt'], columns=range(2,11))\n",
    "df_kmeans = df_kmeans.transpose()\n",
    "df_kmeans.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0, 0.5, 'davies bouldin scores')"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gráficas\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(range(2,df_kmeans.index.max()+1), inertias_np, 'or')\n",
    "plt.plot(range(2,df_kmeans.index.max()+1), inertias_sc, 'b+')\n",
    "plt.plot(range(2,df_kmeans.index.max()+1), inertias_pt, 'ks')\n",
    "plt.xlabel('number of clusters')\n",
    "plt.ylabel('inertias')\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(range(2,df_kmeans.index.max()+1), sil_scores_np, 'or')\n",
    "plt.plot(range(2,df_kmeans.index.max()+1), sil_scores_sc, 'b+')\n",
    "plt.plot(range(2,df_kmeans.index.max()+1), sil_scores_pt, 'ks')\n",
    "plt.xlabel('number of clusters')\n",
    "plt.ylabel('silhouette scores')\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(range(2,df_kmeans.index.max()+1), cal_scores_np, 'or')\n",
    "plt.plot(range(2,df_kmeans.index.max()+1), cal_scores_sc, 'b+')\n",
    "plt.plot(range(2,df_kmeans.index.max()+1), cal_scores_pt, 'ks')\n",
    "plt.xlabel('number of clusters')\n",
    "plt.ylabel('calinski harabasz scores')\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(range(2,df_kmeans.index.max()+1), dav_scores_np, 'or')\n",
    "plt.plot(range(2,df_kmeans.index.max()+1), dav_scores_sc, 'b+')\n",
    "plt.plot(range(2,df_kmeans.index.max()+1), dav_scores_pt, 'ks')\n",
    "plt.xlabel('number of clusters')\n",
    "plt.ylabel('davies bouldin scores')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def clusters_gaussian(data, max_clusters=10):\n",
    "    gauss_scores = []\n",
    "    sil_scores = []\n",
    "    cal_scores = []\n",
    "    dav_scores = []\n",
    "    for i in range(2,max_clusters+1):\n",
    "        gauss = GaussianMixture(i, random_state=72).fit(data)\n",
    "        labels = gauss.predict(data)\n",
    "        score = gauss.score(data)\n",
    "        gauss_scores.append(score)\n",
    "        sil = silhouette_score(X=data, labels=labels)\n",
    "        sil_scores.append(sil)\n",
    "        cal = calinski_harabasz_score(X=data, labels=labels)\n",
    "        cal_scores.append(cal)\n",
    "        dav = davies_bouldin_score(X=data, labels=labels)\n",
    "        dav_scores.append(dav)\n",
    "    return gauss_scores, sil_scores, cal_scores, dav_scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "   silhouette gauss np  calinski gauss np  davies gauss np  \\\n2             0.140430          15.948231         2.258104   \n3             0.137739          13.441898         1.974317   \n4             0.121609          11.223888         1.937475   \n5             0.088460           9.265846         2.221143   \n6             0.092780           9.026629         2.015649   \n\n   silhouette gauss sc  calinski gauss sc  davies gauss sc  \\\n2             0.141303           8.995966         2.301088   \n3             0.097107           9.079189         2.513739   \n4             0.099765           7.586436         2.041934   \n5             0.082408           7.393322         2.169239   \n6             0.083356           7.053722         2.172089   \n\n   silhouette gauss pt  calinski gauss pt  davies gauss pt  \n2             0.103173          11.578432         2.689949  \n3             0.085980           9.237497         2.797421  \n4             0.099326           9.161644         2.396280  \n5             0.093969           8.317390         2.302571  \n6             0.086713           7.297082         2.327979  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>silhouette gauss np</th>\n      <th>calinski gauss np</th>\n      <th>davies gauss np</th>\n      <th>silhouette gauss sc</th>\n      <th>calinski gauss sc</th>\n      <th>davies gauss sc</th>\n      <th>silhouette gauss pt</th>\n      <th>calinski gauss pt</th>\n      <th>davies gauss pt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>0.140430</td>\n      <td>15.948231</td>\n      <td>2.258104</td>\n      <td>0.141303</td>\n      <td>8.995966</td>\n      <td>2.301088</td>\n      <td>0.103173</td>\n      <td>11.578432</td>\n      <td>2.689949</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.137739</td>\n      <td>13.441898</td>\n      <td>1.974317</td>\n      <td>0.097107</td>\n      <td>9.079189</td>\n      <td>2.513739</td>\n      <td>0.085980</td>\n      <td>9.237497</td>\n      <td>2.797421</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.121609</td>\n      <td>11.223888</td>\n      <td>1.937475</td>\n      <td>0.099765</td>\n      <td>7.586436</td>\n      <td>2.041934</td>\n      <td>0.099326</td>\n      <td>9.161644</td>\n      <td>2.396280</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.088460</td>\n      <td>9.265846</td>\n      <td>2.221143</td>\n      <td>0.082408</td>\n      <td>7.393322</td>\n      <td>2.169239</td>\n      <td>0.093969</td>\n      <td>8.317390</td>\n      <td>2.302571</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.092780</td>\n      <td>9.026629</td>\n      <td>2.015649</td>\n      <td>0.083356</td>\n      <td>7.053722</td>\n      <td>2.172089</td>\n      <td>0.086713</td>\n      <td>7.297082</td>\n      <td>2.327979</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clústeres por GMM, datos sin normalizar\n",
    "max_clusters = 10\n",
    "gauss_scores_np, sil_scores_np, cal_scores_np, dav_scores_np = clusters_gaussian(data=data, max_clusters=max_clusters)\n",
    "# clústeres por GMM, Standard Scaler\n",
    "gauss_scores_sc, sil_scores_sc, cal_scores_sc, dav_scores_sc = clusters_gaussian(data=data_sc, max_clusters=max_clusters)\n",
    "# clústeres por KMeans, PowerTransformer\n",
    "gauss_scores_pt, sil_scores_pt, cal_scores_pt, dav_scores_pt = clusters_gaussian(data=data_pt, max_clusters=max_clusters)\n",
    "# Dataframe con métricas de clustering de KMeans\n",
    "df_gauss = pd.DataFrame(data=[sil_scores_np, cal_scores_np, dav_scores_np, sil_scores_sc, cal_scores_sc, dav_scores_sc, sil_scores_pt, cal_scores_pt, dav_scores_pt], index=['silhouette gauss np', 'calinski gauss np', 'davies gauss np', 'silhouette gauss sc', 'calinski gauss sc', 'davies gauss sc', 'silhouette gauss pt', 'calinski gauss pt', 'davies gauss pt'], columns=range(2,max_clusters+1))\n",
    "df_gauss = df_gauss.transpose()\n",
    "df_gauss.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0, 0.5, 'davies bouldin scores')"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gráficas\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(range(2,df_gauss.index.max()+1), gauss_scores_np, 'or')\n",
    "plt.plot(range(2,df_gauss.index.max()+1), gauss_scores_sc, 'b+')\n",
    "plt.plot(range(2,df_gauss.index.max()+1), gauss_scores_pt, 'ks')\n",
    "plt.xlabel('number of clusters')\n",
    "plt.ylabel('inertias')\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(range(2,df_gauss.index.max()+1), sil_scores_np, 'or')\n",
    "plt.plot(range(2,df_gauss.index.max()+1), sil_scores_sc, 'b+')\n",
    "plt.plot(range(2,df_gauss.index.max()+1), sil_scores_pt, 'ks')\n",
    "plt.xlabel('number of clusters')\n",
    "plt.ylabel('silhouette scores')\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(range(2,df_gauss.index.max()+1), cal_scores_np, 'or')\n",
    "plt.plot(range(2,df_gauss.index.max()+1), cal_scores_sc, 'b+')\n",
    "plt.plot(range(2,df_gauss.index.max()+1), cal_scores_pt, 'ks')\n",
    "plt.xlabel('number of clusters')\n",
    "plt.ylabel('calinski harabasz scores')\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(range(2,df_gauss.index.max()+1), dav_scores_np, 'or')\n",
    "plt.plot(range(2,df_gauss.index.max()+1), dav_scores_sc, 'b+')\n",
    "plt.plot(range(2,df_gauss.index.max()+1), dav_scores_pt, 'ks')\n",
    "plt.xlabel('number of clusters')\n",
    "plt.ylabel('davies bouldin scores')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def clusters_spectral(data, max_clusters=10):\n",
    "    sil_scores = []\n",
    "    cal_scores = []\n",
    "    dav_scores = []\n",
    "    for i in range(2,max_clusters+1):\n",
    "        sc = SpectralClustering(i, random_state=72).fit(data)\n",
    "        labels = sc.labels_\n",
    "        sil = silhouette_score(X=data, labels=labels)\n",
    "        sil_scores.append(sil)\n",
    "        cal = calinski_harabasz_score(X=data, labels=labels)\n",
    "        cal_scores.append(cal)\n",
    "        dav = davies_bouldin_score(X=data, labels=labels)\n",
    "        dav_scores.append(dav)\n",
    "    return sil_scores, cal_scores, dav_scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "   silhouette spèctral np  calinski spectral np  davies spectral np  \\\n2                0.384709              4.323644            0.466401   \n3                0.384709              4.323644            0.466401   \n4                0.312515              4.235392            0.479128   \n5                0.312515              4.235392            0.479128   \n6                0.384709              4.323644            0.466401   \n\n   silhouette spectral sc  calinski spectral sc  davies spectral sc  \\\n2                0.072662              9.213499            2.592379   \n3               -0.023366              3.267420            2.116766   \n4                0.009084              5.097932            2.515847   \n5                0.016349              4.671844            3.274680   \n6                0.018762              4.734451            2.538218   \n\n   silhouette spectral pt  calinski spectral pt  davies spectral pt  \n2                0.058295              5.064337            2.951708  \n3                0.032183              3.873963            3.380819  \n4                0.033596              4.561816            2.944617  \n5                0.041663              5.055261            2.571906  \n6                0.018136              4.259066            2.469577  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>silhouette spèctral np</th>\n      <th>calinski spectral np</th>\n      <th>davies spectral np</th>\n      <th>silhouette spectral sc</th>\n      <th>calinski spectral sc</th>\n      <th>davies spectral sc</th>\n      <th>silhouette spectral pt</th>\n      <th>calinski spectral pt</th>\n      <th>davies spectral pt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>0.384709</td>\n      <td>4.323644</td>\n      <td>0.466401</td>\n      <td>0.072662</td>\n      <td>9.213499</td>\n      <td>2.592379</td>\n      <td>0.058295</td>\n      <td>5.064337</td>\n      <td>2.951708</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.384709</td>\n      <td>4.323644</td>\n      <td>0.466401</td>\n      <td>-0.023366</td>\n      <td>3.267420</td>\n      <td>2.116766</td>\n      <td>0.032183</td>\n      <td>3.873963</td>\n      <td>3.380819</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.312515</td>\n      <td>4.235392</td>\n      <td>0.479128</td>\n      <td>0.009084</td>\n      <td>5.097932</td>\n      <td>2.515847</td>\n      <td>0.033596</td>\n      <td>4.561816</td>\n      <td>2.944617</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.312515</td>\n      <td>4.235392</td>\n      <td>0.479128</td>\n      <td>0.016349</td>\n      <td>4.671844</td>\n      <td>3.274680</td>\n      <td>0.041663</td>\n      <td>5.055261</td>\n      <td>2.571906</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.384709</td>\n      <td>4.323644</td>\n      <td>0.466401</td>\n      <td>0.018762</td>\n      <td>4.734451</td>\n      <td>2.538218</td>\n      <td>0.018136</td>\n      <td>4.259066</td>\n      <td>2.469577</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clústeres por Spectral Clustering, datos sin normalizar\n",
    "max_clusters=10\n",
    "sil_scores_np, cal_scores_np, dav_scores_np = clusters_spectral(data=data, max_clusters=max_clusters)\n",
    "# clústeres por Spectral Clustering, Standard Scaler\n",
    "sil_scores_sc, cal_scores_sc, dav_scores_sc = clusters_spectral(data=data_sc, max_clusters=max_clusters)\n",
    "# clústeres por Spectral Clustering, PowerTransformer\n",
    "sil_scores_pt, cal_scores_pt, dav_scores_pt = clusters_spectral(data=data_pt, max_clusters=max_clusters)\n",
    "# Dataframe con métricas de clustering de KMeans\n",
    "df_spectral = pd.DataFrame(data=[sil_scores_np, cal_scores_np, dav_scores_np, sil_scores_sc, cal_scores_sc, dav_scores_sc, sil_scores_pt, cal_scores_pt, dav_scores_pt], index=['silhouette spèctral np', 'calinski spectral np', 'davies spectral np', 'silhouette spectral sc', 'calinski spectral sc', 'davies spectral sc', 'silhouette spectral pt', 'calinski spectral pt', 'davies spectral pt'], columns=range(2,max_clusters+1))\n",
    "df_spectral = df_spectral.transpose()\n",
    "df_spectral.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0, 0.5, 'davies bouldin scores')"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gráficas\n",
    "plt.subplot(2,2,1)\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(range(2,df_spectral.index.max()+1), sil_scores_np, 'or')\n",
    "plt.plot(range(2,df_spectral.index.max()+1), sil_scores_sc, 'b+')\n",
    "plt.plot(range(2,df_spectral.index.max()+1), sil_scores_pt, 'ks')\n",
    "plt.xlabel('number of clusters')\n",
    "plt.ylabel('silhouette scores')\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(range(2,df_spectral.index.max()+1), cal_scores_np, 'or')\n",
    "plt.plot(range(2,df_spectral.index.max()+1), cal_scores_sc, 'b+')\n",
    "plt.plot(range(2,df_spectral.index.max()+1), cal_scores_pt, 'ks')\n",
    "plt.xlabel('number of clusters')\n",
    "plt.ylabel('calinski harabasz scores')\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(range(2,df_spectral.index.max()+1), dav_scores_np, 'or')\n",
    "plt.plot(range(2,df_spectral.index.max()+1), dav_scores_sc, 'b+')\n",
    "plt.plot(range(2,df_spectral.index.max()+1), dav_scores_pt, 'ks')\n",
    "plt.xlabel('number of clusters')\n",
    "plt.ylabel('davies bouldin scores')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "   silhouette kmeans np  calinski kmeans np  davies kmeans np  \\\n2              0.140430           15.948231          2.258104   \n3              0.141865           13.543720          1.953296   \n4              0.104275           11.728366          2.177642   \n5              0.098943           10.313543          2.024446   \n6              0.103143            9.694866          1.749558   \n\n   silhouette kmeans sc  calinski kmeans sc  davies kmeans sc  \\\n2              0.115895           10.520811          2.745652   \n3              0.096446           10.074285          2.429310   \n4              0.096957            8.989544          2.212793   \n5              0.088588            8.588638          2.195654   \n6              0.101929            8.109551          1.998565   \n\n   silhouette kmeans pt  calinski kmeans pt  davies kmeans pt  \\\n2              0.103173           11.578432          2.689949   \n3              0.102325           10.640033          2.487609   \n4              0.088649            9.166728          2.556416   \n5              0.091740            8.539001          2.232042   \n6              0.084863            7.459235          2.188218   \n\n   silhouette gauss np  ...  davies gauss pt  silhouette spèctral np  \\\n2             0.140430  ...         2.689949                0.384709   \n3             0.137739  ...         2.797421                0.384709   \n4             0.121609  ...         2.396280                0.312515   \n5             0.088460  ...         2.302571                0.312515   \n6             0.092780  ...         2.327979                0.384709   \n\n   calinski spectral np  davies spectral np  silhouette spectral sc  \\\n2              4.323644            0.466401                0.072662   \n3              4.323644            0.466401               -0.023366   \n4              4.235392            0.479128                0.009084   \n5              4.235392            0.479128                0.016349   \n6              4.323644            0.466401                0.018762   \n\n   calinski spectral sc  davies spectral sc  silhouette spectral pt  \\\n2              9.213499            2.592379                0.058295   \n3              3.267420            2.116766                0.032183   \n4              5.097932            2.515847                0.033596   \n5              4.671844            3.274680                0.041663   \n6              4.734451            2.538218                0.018136   \n\n   calinski spectral pt  davies spectral pt  \n2              5.064337            2.951708  \n3              3.873963            3.380819  \n4              4.561816            2.944617  \n5              5.055261            2.571906  \n6              4.259066            2.469577  \n\n[5 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>silhouette kmeans np</th>\n      <th>calinski kmeans np</th>\n      <th>davies kmeans np</th>\n      <th>silhouette kmeans sc</th>\n      <th>calinski kmeans sc</th>\n      <th>davies kmeans sc</th>\n      <th>silhouette kmeans pt</th>\n      <th>calinski kmeans pt</th>\n      <th>davies kmeans pt</th>\n      <th>silhouette gauss np</th>\n      <th>...</th>\n      <th>davies gauss pt</th>\n      <th>silhouette spèctral np</th>\n      <th>calinski spectral np</th>\n      <th>davies spectral np</th>\n      <th>silhouette spectral sc</th>\n      <th>calinski spectral sc</th>\n      <th>davies spectral sc</th>\n      <th>silhouette spectral pt</th>\n      <th>calinski spectral pt</th>\n      <th>davies spectral pt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>0.140430</td>\n      <td>15.948231</td>\n      <td>2.258104</td>\n      <td>0.115895</td>\n      <td>10.520811</td>\n      <td>2.745652</td>\n      <td>0.103173</td>\n      <td>11.578432</td>\n      <td>2.689949</td>\n      <td>0.140430</td>\n      <td>...</td>\n      <td>2.689949</td>\n      <td>0.384709</td>\n      <td>4.323644</td>\n      <td>0.466401</td>\n      <td>0.072662</td>\n      <td>9.213499</td>\n      <td>2.592379</td>\n      <td>0.058295</td>\n      <td>5.064337</td>\n      <td>2.951708</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.141865</td>\n      <td>13.543720</td>\n      <td>1.953296</td>\n      <td>0.096446</td>\n      <td>10.074285</td>\n      <td>2.429310</td>\n      <td>0.102325</td>\n      <td>10.640033</td>\n      <td>2.487609</td>\n      <td>0.137739</td>\n      <td>...</td>\n      <td>2.797421</td>\n      <td>0.384709</td>\n      <td>4.323644</td>\n      <td>0.466401</td>\n      <td>-0.023366</td>\n      <td>3.267420</td>\n      <td>2.116766</td>\n      <td>0.032183</td>\n      <td>3.873963</td>\n      <td>3.380819</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.104275</td>\n      <td>11.728366</td>\n      <td>2.177642</td>\n      <td>0.096957</td>\n      <td>8.989544</td>\n      <td>2.212793</td>\n      <td>0.088649</td>\n      <td>9.166728</td>\n      <td>2.556416</td>\n      <td>0.121609</td>\n      <td>...</td>\n      <td>2.396280</td>\n      <td>0.312515</td>\n      <td>4.235392</td>\n      <td>0.479128</td>\n      <td>0.009084</td>\n      <td>5.097932</td>\n      <td>2.515847</td>\n      <td>0.033596</td>\n      <td>4.561816</td>\n      <td>2.944617</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.098943</td>\n      <td>10.313543</td>\n      <td>2.024446</td>\n      <td>0.088588</td>\n      <td>8.588638</td>\n      <td>2.195654</td>\n      <td>0.091740</td>\n      <td>8.539001</td>\n      <td>2.232042</td>\n      <td>0.088460</td>\n      <td>...</td>\n      <td>2.302571</td>\n      <td>0.312515</td>\n      <td>4.235392</td>\n      <td>0.479128</td>\n      <td>0.016349</td>\n      <td>4.671844</td>\n      <td>3.274680</td>\n      <td>0.041663</td>\n      <td>5.055261</td>\n      <td>2.571906</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.103143</td>\n      <td>9.694866</td>\n      <td>1.749558</td>\n      <td>0.101929</td>\n      <td>8.109551</td>\n      <td>1.998565</td>\n      <td>0.084863</td>\n      <td>7.459235</td>\n      <td>2.188218</td>\n      <td>0.092780</td>\n      <td>...</td>\n      <td>2.327979</td>\n      <td>0.384709</td>\n      <td>4.323644</td>\n      <td>0.466401</td>\n      <td>0.018762</td>\n      <td>4.734451</td>\n      <td>2.538218</td>\n      <td>0.018136</td>\n      <td>4.259066</td>\n      <td>2.469577</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 27 columns</p>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_todos = pd.concat([df_kmeans, df_gauss, df_spectral], axis=1)\n",
    "df_todos.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "         max_degree_b1d  max_degree_b2c  max_degree_b2i  max_degree_gi  \\\nsubject                                                                  \n21100                 0               5               6             10   \n21101                 0               5               5              5   \n21102                -2               5               6              5   \n21103                 1               4               5              5   \n21104                -2               6               5              6   \n\n         mean_eccentricity_ac  mean_eccentricity_b2i  mean_eccentricity_b2d  \\\nsubject                                                                       \n21100               13.546875              11.312500               2.843750   \n21101               10.718750              17.062500              -0.812500   \n21102               14.703125              14.531250              -1.921875   \n21103               16.250000              14.078125               2.625000   \n21104               11.906250              18.000000              -4.515625   \n\n         mean_eccentricity_gc  mean_eccentricity_gd  EX2_score  ...  IRI_PD  \\\nsubject                                                         ...           \n21100               19.046875              6.671875          8  ...    11.0   \n21101               13.156250             -7.343750          8  ...     6.0   \n21102               11.453125             -4.250000          1  ...    10.0   \n21103               16.718750              0.484375          8  ...    12.0   \n21104               19.546875              6.968750          5  ...     8.0   \n\n         RPQ AR  exposure_level_high  exposure_level_low  gender_F  gender_M  \\\nsubject                                                                        \n21100      20.0                    1                   0         1         0   \n21101      33.0                    1                   0         0         1   \n21102      13.0                    0                   1         0         1   \n21103      16.0                    1                   0         0         1   \n21104      16.0                    1                   0         0         1   \n\n         victims_self_no  victims_self_yes  labels kmeans  labels gmm  \nsubject                                                                \n21100                  0                 1              0           2  \n21101                  0                 1              2           0  \n21102                  0                 1              1           1  \n21103                  0                 1              0           2  \n21104                  0                 1              1           0  \n\n[5 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>max_degree_b1d</th>\n      <th>max_degree_b2c</th>\n      <th>max_degree_b2i</th>\n      <th>max_degree_gi</th>\n      <th>mean_eccentricity_ac</th>\n      <th>mean_eccentricity_b2i</th>\n      <th>mean_eccentricity_b2d</th>\n      <th>mean_eccentricity_gc</th>\n      <th>mean_eccentricity_gd</th>\n      <th>EX2_score</th>\n      <th>...</th>\n      <th>IRI_PD</th>\n      <th>RPQ AR</th>\n      <th>exposure_level_high</th>\n      <th>exposure_level_low</th>\n      <th>gender_F</th>\n      <th>gender_M</th>\n      <th>victims_self_no</th>\n      <th>victims_self_yes</th>\n      <th>labels kmeans</th>\n      <th>labels gmm</th>\n    </tr>\n    <tr>\n      <th>subject</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21100</th>\n      <td>0</td>\n      <td>5</td>\n      <td>6</td>\n      <td>10</td>\n      <td>13.546875</td>\n      <td>11.312500</td>\n      <td>2.843750</td>\n      <td>19.046875</td>\n      <td>6.671875</td>\n      <td>8</td>\n      <td>...</td>\n      <td>11.0</td>\n      <td>20.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>21101</th>\n      <td>0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>10.718750</td>\n      <td>17.062500</td>\n      <td>-0.812500</td>\n      <td>13.156250</td>\n      <td>-7.343750</td>\n      <td>8</td>\n      <td>...</td>\n      <td>6.0</td>\n      <td>33.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21102</th>\n      <td>-2</td>\n      <td>5</td>\n      <td>6</td>\n      <td>5</td>\n      <td>14.703125</td>\n      <td>14.531250</td>\n      <td>-1.921875</td>\n      <td>11.453125</td>\n      <td>-4.250000</td>\n      <td>1</td>\n      <td>...</td>\n      <td>10.0</td>\n      <td>13.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>21103</th>\n      <td>1</td>\n      <td>4</td>\n      <td>5</td>\n      <td>5</td>\n      <td>16.250000</td>\n      <td>14.078125</td>\n      <td>2.625000</td>\n      <td>16.718750</td>\n      <td>0.484375</td>\n      <td>8</td>\n      <td>...</td>\n      <td>12.0</td>\n      <td>16.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>21104</th>\n      <td>-2</td>\n      <td>6</td>\n      <td>5</td>\n      <td>6</td>\n      <td>11.906250</td>\n      <td>18.000000</td>\n      <td>-4.515625</td>\n      <td>19.546875</td>\n      <td>6.968750</td>\n      <td>5</td>\n      <td>...</td>\n      <td>8.0</td>\n      <td>16.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 28 columns</p>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parece que los mejores modelos son KMeans y GMM con 3 clústeres sin escalizar\n",
    "data_clusters = data.copy()\n",
    "kmeans = KMeans(3, random_state=72).fit(data)\n",
    "labels_k = kmeans.labels_\n",
    "data_clusters['labels kmeans'] = labels_k\n",
    "gauss = GaussianMixture(3, random_state=72).fit(data)\n",
    "labels_g = gauss.predict(data)\n",
    "data_clusters['labels gmm'] = labels_g\n",
    "data_clusters.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "data_clusters.to_csv('clusters_kmeans_gmm_3.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Validación clústeres con modelos de clasificación"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "(70, 26)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data_clusters.drop(['labels kmeans', 'labels gmm'], axis=1).copy()\n",
    "y = data_clusters['labels gmm'].copy()\n",
    "# separación datos de prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=77, stratify=y)\n",
    "y_train_label = LabelEncoder().fit_transform(y_train)\n",
    "y_test_label = LabelEncoder().fit_transform(y_test)\n",
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69da99a584bf457899e3148b8aaff802"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'colsample_bytree': 0.736213098005421, 'eta': 0.2480338929576088, 'max_depth': 3, 'n_estimators': 66, 'subsample': 0.819624579463738}\n",
      "best accuracy: 0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "# Modelo XGBoosting sin preprocesar datos\n",
    "param_space =dict(n_estimators=range(1,100), max_depth=range(3,10), subsample=uniform(0.1,0.9), eta=uniform(0,1), colsample_bytree=uniform(0.1,0.9))\n",
    "@scheduler.parallel(n_jobs=-1)\n",
    "def objective(**params):\n",
    "    global X_train, y_train_label\n",
    "    model = XGBClassifier(**params)\n",
    "    error= cross_val_score(estimator = model, X= X_train, y= y_train_label, scoring='accuracy', cv=5).mean()\n",
    "    return error\n",
    "tuner = Tuner(param_space, objective)\n",
    "best_results = tuner.maximize()\n",
    "print('best parameters:', best_results['best_params'])\n",
    "print('best accuracy:', best_results['best_objective'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9285714285714286 0.04517539514526258\n",
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "params = best_results['best_params']\n",
    "model = XGBClassifier(**params)\n",
    "scores = cross_val_score(estimator = model, X= X_train, y= y_train_label, scoring='accuracy', cv=5)\n",
    "print(scores.mean(), scores.std())\n",
    "model.fit(X_train, y_train_label)\n",
    "print(model.score(X_test, y_test_label))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a5ac075c160408c8fb3e0bc30ab324d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'colsample_bytree': 0.7251311634844219, 'eta': 0.29095852050979, 'max_depth': 6, 'n_estimators': 49, 'subsample': 0.5483997033213193}\n",
      "best accuracy: 0.9285714285714285\n"
     ]
    }
   ],
   "source": [
    "# Modelo XGBoost con escalizador\n",
    "param_space =dict(n_estimators=range(1,100), max_depth=range(3,10), subsample=uniform(0.1,0.9), eta=uniform(0,1), colsample_bytree=uniform(0.1,0.9))\n",
    "@scheduler.parallel(n_jobs=-1)\n",
    "def objective(**params):\n",
    "    global X_train, y_train_label\n",
    "    numeric_cols = X_train.select_dtypes(include=['float64','int64']).columns.to_list()\n",
    "    preprocessor = ColumnTransformer([('scale', StandardScaler(), numeric_cols)], remainder='passthrough')\n",
    "    pipe = Pipeline([('preprocessing', preprocessor),('model', XGBClassifier(**params))])\n",
    "    error = cross_val_score(estimator = pipe, X= X_train, y= y_train_label, scoring='accuracy', cv=5).mean()\n",
    "    return error\n",
    "tuner = Tuner(param_space, objective)\n",
    "best_results = tuner.maximize()\n",
    "print('best parameters:', best_results['best_params'])\n",
    "print('best accuracy:', best_results['best_objective'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9285714285714285 0.06388765649999402\n",
      "0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "params = best_results['best_params']\n",
    "numeric_cols = X_train.select_dtypes(include=['float64','int64']).columns.to_list()\n",
    "preprocessor = ColumnTransformer([('scale', StandardScaler(), numeric_cols)], remainder='passthrough')\n",
    "pipe = Pipeline([('preprocessing', preprocessor),('model', XGBClassifier(**params))])\n",
    "scores = cross_val_score(estimator = pipe, X= X_train, y= y_train_label, scoring='accuracy', cv=5)\n",
    "print(scores.mean(), scores.std())\n",
    "pipe.fit(X_train, y_train_label)\n",
    "print(pipe.score(X_test, y_test_label))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0653ae9fcd9e444194952d06de0fcfc7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'colsample_bytree': 0.955614797985831, 'eta': 0.2761123520020293, 'max_depth': 6, 'n_estimators': 33, 'subsample': 0.3405732785725569}\n",
      "best accuracy: 0.9428571428571428\n"
     ]
    }
   ],
   "source": [
    "# Modelo XGBoost con standard_scaler y min_max_scaler\n",
    "param_space =dict(n_estimators=range(1,100), max_depth=range(3,10), subsample=uniform(0.1,0.9), eta=uniform(0,1), colsample_bytree=uniform(0.1,0.9))\n",
    "@scheduler.parallel(n_jobs=-1)\n",
    "def objective(**params):\n",
    "    global X_train, y_train_label\n",
    "    continuas_cols = X_train.select_dtypes(include=['float64']).columns.to_list()\n",
    "    discretas_cols = X_train.select_dtypes(include=['int64']).columns.to_list()\n",
    "    preprocessor = ColumnTransformer([('scaler', StandardScaler(), continuas_cols), ('min_max', MinMaxScaler(), discretas_cols)], remainder='passthrough')\n",
    "    pipe = Pipeline([('preprocessing', preprocessor),('model', XGBClassifier(**params))])\n",
    "    error = cross_val_score(estimator = pipe, X= X_train, y= y_train_label, scoring='accuracy', cv=5).mean()\n",
    "    return error\n",
    "tuner = Tuner(param_space, objective)\n",
    "best_results = tuner.maximize()\n",
    "print('best parameters:', best_results['best_params'])\n",
    "print('best accuracy:', best_results['best_objective'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9428571428571428 0.05345224838248489\n",
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "params = best_results['best_params']\n",
    "continuas_cols = X_train.select_dtypes(include=['float64']).columns.to_list()\n",
    "discretas_cols = X_train.select_dtypes(include=['int64']).columns.to_list()\n",
    "preprocessor = ColumnTransformer([('scaler', StandardScaler(), continuas_cols), ('min_max', MinMaxScaler(), discretas_cols)], remainder='passthrough')\n",
    "pipe = Pipeline([('preprocessing', preprocessor),('model', XGBClassifier(**params))])\n",
    "scores = cross_val_score(estimator = pipe, X= X_train, y= y_train_label, scoring='accuracy', cv=5)\n",
    "print(scores.mean(), scores.std())\n",
    "pipe.fit(X_train, y_train_label)\n",
    "print(pipe.score(X_test, y_test_label))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b7b3ab9626024806a31c6a89e6f02b23"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'colsample_bytree': 0.5726964014056182, 'eta': 0.5942453661633827, 'max_depth': 8, 'n_estimators': 22, 'subsample': 0.8397693232911679}\n",
      "best accuracy: 0.9285714285714285\n"
     ]
    }
   ],
   "source": [
    "# Modelo XGBoost con power transformer y min_max_scaler\n",
    "param_space =dict(n_estimators=range(1,100), max_depth=range(3,10), subsample=uniform(0.1,0.9), eta=uniform(0,1), colsample_bytree=uniform(0.1,0.9))\n",
    "@scheduler.parallel(n_jobs=-1)\n",
    "def objective(**params):\n",
    "    global X_train, y_train_label\n",
    "    continuas_cols = X_train.select_dtypes(include=['float64']).columns.to_list()\n",
    "    discretas_cols = X_train.select_dtypes(include=['int64']).columns.to_list()\n",
    "    preprocessor = ColumnTransformer([('pt', PowerTransformer(), continuas_cols), ('min_max', MinMaxScaler(), discretas_cols)], remainder='passthrough')\n",
    "    pipe = Pipeline([('preprocessing', preprocessor),('model', XGBClassifier(**params))])\n",
    "    error = cross_val_score(estimator = pipe, X= X_train, y= y_train_label, scoring='accuracy', cv=5).mean()\n",
    "    return error\n",
    "tuner = Tuner(param_space, objective)\n",
    "best_results = tuner.maximize()\n",
    "print('best parameters:', best_results['best_params'])\n",
    "print('best accuracy:', best_results['best_objective'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9285714285714285 0.06388765649999402\n",
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "params = best_results['best_params']\n",
    "continuas_cols = X_train.select_dtypes(include=['float64']).columns.to_list()\n",
    "discretas_cols = X_train.select_dtypes(include=['int64']).columns.to_list()\n",
    "preprocessor = ColumnTransformer([('pt', PowerTransformer(), continuas_cols), ('min_max', MinMaxScaler(), discretas_cols)], remainder='passthrough')\n",
    "pipe = Pipeline([('preprocessing', preprocessor),('model', XGBClassifier(**params))])\n",
    "scores = cross_val_score(estimator = pipe, X= X_train, y= y_train_label, scoring='accuracy', cv=5)\n",
    "print(scores.mean(), scores.std())\n",
    "pipe.fit(X_train, y_train_label)\n",
    "print(pipe.score(X_test, y_test_label))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9428571428571428 0.05345224838248489\n",
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "# Mejor modelo\n",
    "params= {'colsample_bytree': 0.955614797985831, 'eta': 0.2761123520020293, 'max_depth': 6, 'n_estimators': 33, 'subsample': 0.3405732785725569}\n",
    "continuas_cols = X_train.select_dtypes(include=['float64']).columns.to_list()\n",
    "discretas_cols = X_train.select_dtypes(include=['int64']).columns.to_list()\n",
    "preprocessor = ColumnTransformer([('scaler', StandardScaler(), continuas_cols), ('min_max', MinMaxScaler(), discretas_cols)], remainder='passthrough')\n",
    "pipe = Pipeline([('preprocessing', preprocessor),('model', XGBClassifier(**params))])\n",
    "scores = cross_val_score(estimator = pipe, X= X_train, y= y_train_label, scoring='accuracy', cv=5)\n",
    "print(scores.mean(), scores.std())\n",
    "pipe.fit(X_train, y_train_label)\n",
    "print(pipe.score(X_test, y_test_label))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "                       mean importance\nIRI_PT                        0.239773\nRPQ AR                        0.084091\nAL                            0.063636\nschool_years                  0.031818\nRPQ AP                        0.017045\nIRI_PD                        0.011364\nmean_eccentricity_b2i         0.010227\nIRI_EC                        0.005682\nmean_eccentricity_ti          0.005682\nEX2_score                     0.004545\nvictims_self_no               0.000000\ngender_M                      0.000000\ngender_F                      0.000000\nexposure_level_low            0.000000\nexposure_level_high           0.000000\nmax_degree_b1d                0.000000\nAN                            0.000000\nTD                            0.000000\nmax_degree_b2c                0.000000\nmean_eccentricity_gd          0.000000\nmean_eccentricity_gc          0.000000\nmean_eccentricity_b2d         0.000000\nmean_eccentricity_ac          0.000000\nmax_degree_gi                 0.000000\nmax_degree_b2i                0.000000\nvictims_self_yes              0.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>IRI_PT</th>\n      <td>0.239773</td>\n    </tr>\n    <tr>\n      <th>RPQ AR</th>\n      <td>0.084091</td>\n    </tr>\n    <tr>\n      <th>AL</th>\n      <td>0.063636</td>\n    </tr>\n    <tr>\n      <th>school_years</th>\n      <td>0.031818</td>\n    </tr>\n    <tr>\n      <th>RPQ AP</th>\n      <td>0.017045</td>\n    </tr>\n    <tr>\n      <th>IRI_PD</th>\n      <td>0.011364</td>\n    </tr>\n    <tr>\n      <th>mean_eccentricity_b2i</th>\n      <td>0.010227</td>\n    </tr>\n    <tr>\n      <th>IRI_EC</th>\n      <td>0.005682</td>\n    </tr>\n    <tr>\n      <th>mean_eccentricity_ti</th>\n      <td>0.005682</td>\n    </tr>\n    <tr>\n      <th>EX2_score</th>\n      <td>0.004545</td>\n    </tr>\n    <tr>\n      <th>victims_self_no</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>gender_M</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>gender_F</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>exposure_level_low</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>exposure_level_high</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max_degree_b1d</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>AN</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>TD</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max_degree_b2c</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>mean_eccentricity_gd</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>mean_eccentricity_gc</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>mean_eccentricity_b2d</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>mean_eccentricity_ac</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max_degree_gi</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max_degree_b2i</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>victims_self_yes</th>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Análisis de relevancia\n",
    "y_label = LabelEncoder().fit_transform(y)\n",
    "model = pipe.fit(X, y_label)\n",
    "r = permutation_importance(model, X, y_label,n_repeats=10,random_state=0, scoring='accuracy')\n",
    "importancia_atributos = pd.DataFrame(data=[r.importances_mean], columns=X.columns, index=['mean importance']).transpose()\n",
    "importancia_atributos.sort_values(by='mean importance', ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "importancia_atributos.to_csv('importancia atributos clustering.csv', index_label='feature')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "         labels gmm predicted\nsubject                      \n21147             0         1\n21111             0         1\n22103             2         1\n21110             1         2\n21109             0         1\n21121             0         1\n22108             0         1\n24043             2         1\n21123             2         1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>labels gmm</th>\n      <th>predicted</th>\n    </tr>\n    <tr>\n      <th>subject</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21147</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>21111</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>22103</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>21110</th>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>21109</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>21121</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>22108</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24043</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>21123</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracción sujetos mal clasificados\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train_label = le.fit_transform(y_train)\n",
    "y_test_label = le.fit_transform(y_test)\n",
    "model = pipe.fit(X_train, y_train_label)\n",
    "\n",
    "df_errados = pd.DataFrame(columns=['predicted'])\n",
    "# errores dataset de entrenamiento\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X_train, y_train_label)):\n",
    "    model.fit(X_train.iloc[train_index], y_train_label[train_index])\n",
    "    y_est = model.predict(X_train.iloc[test_index])\n",
    "    errado = test_index[y_train_label[test_index] != y_est]\n",
    "    y_pred = le.inverse_transform(y_est)\n",
    "    y_p_df = pd.DataFrame(data=(y_pred), index=test_index, columns=['predicted'])\n",
    "    errado_idx = pd.Index(errado)\n",
    "    y_errados = y_p_df.loc[errado_idx].copy()\n",
    "    df_errados = pd.concat([df_errados, y_errados], ignore_index=False)\n",
    "y_t = y_train.reset_index().copy()\n",
    "df_errados = pd.merge(y_t, df_errados, how='inner', left_index=True, right_index=True)\n",
    "df_errados.set_index('subject', inplace=True)\n",
    "\n",
    "# errores dataset de prueba\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_pred = le.inverse_transform(y_test_pred)\n",
    "y_test_pred_df = pd.DataFrame(data=y_test_pred, index=y_test.index, columns=['predicted'])\n",
    "test_errados_df = pd.merge(y_test, y_test_pred_df, left_index=True, right_index=True)\n",
    "test_errados_df = test_errados_df[test_errados_df['labels gmm'] != test_errados_df['predicted']]\n",
    "\n",
    "df_errados = pd.concat([df_errados, test_errados_df], ignore_index=False)\n",
    "df_errados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "         labels gmm_x predicted  max_degree_b1d  max_degree_b2c  \\\nsubject                                                           \n21147               0         1              -1               6   \n21111               0         1              -1               5   \n22103               2         1               2               5   \n21110               1         2              -2               5   \n21109               0         1               1               6   \n\n         max_degree_b2i  max_degree_gi  mean_eccentricity_ac  \\\nsubject                                                        \n21147                 5              6             11.812500   \n21111                 5              5             12.718750   \n22103                 5              5             10.859375   \n21110                 4              5             11.750000   \n21109                 4              4             13.406250   \n\n         mean_eccentricity_b2i  mean_eccentricity_b2d  mean_eccentricity_gc  \\\nsubject                                                                       \n21147                13.656250               3.359375             16.953125   \n21111                16.296875               0.984375             12.265625   \n22103                13.765625              -2.140625             11.875000   \n21110                11.859375               2.406250             12.359375   \n21109                15.046875               1.562500             16.640625   \n\n         ...  IRI_PD  RPQ AR  exposure_level_high  exposure_level_low  \\\nsubject  ...                                                            \n21147    ...     6.0    16.0                    1                   0   \n21111    ...    10.0    24.0                    1                   0   \n22103    ...    17.0    15.0                    0                   1   \n21110    ...    11.0    14.0                    1                   0   \n21109    ...     7.0    21.0                    1                   0   \n\n         gender_F  gender_M  victims_self_no  victims_self_yes  labels kmeans  \\\nsubject                                                                         \n21147           0         1                0                 1              1   \n21111           1         0                0                 1              2   \n22103           0         1                1                 0              0   \n21110           0         1                0                 1              1   \n21109           0         1                0                 1              2   \n\n         labels gmm_y  \nsubject                \n21147               0  \n21111               0  \n22103               2  \n21110               1  \n21109               0  \n\n[5 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>labels gmm_x</th>\n      <th>predicted</th>\n      <th>max_degree_b1d</th>\n      <th>max_degree_b2c</th>\n      <th>max_degree_b2i</th>\n      <th>max_degree_gi</th>\n      <th>mean_eccentricity_ac</th>\n      <th>mean_eccentricity_b2i</th>\n      <th>mean_eccentricity_b2d</th>\n      <th>mean_eccentricity_gc</th>\n      <th>...</th>\n      <th>IRI_PD</th>\n      <th>RPQ AR</th>\n      <th>exposure_level_high</th>\n      <th>exposure_level_low</th>\n      <th>gender_F</th>\n      <th>gender_M</th>\n      <th>victims_self_no</th>\n      <th>victims_self_yes</th>\n      <th>labels kmeans</th>\n      <th>labels gmm_y</th>\n    </tr>\n    <tr>\n      <th>subject</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21147</th>\n      <td>0</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>6</td>\n      <td>5</td>\n      <td>6</td>\n      <td>11.812500</td>\n      <td>13.656250</td>\n      <td>3.359375</td>\n      <td>16.953125</td>\n      <td>...</td>\n      <td>6.0</td>\n      <td>16.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21111</th>\n      <td>0</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>12.718750</td>\n      <td>16.296875</td>\n      <td>0.984375</td>\n      <td>12.265625</td>\n      <td>...</td>\n      <td>10.0</td>\n      <td>24.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22103</th>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>10.859375</td>\n      <td>13.765625</td>\n      <td>-2.140625</td>\n      <td>11.875000</td>\n      <td>...</td>\n      <td>17.0</td>\n      <td>15.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>21110</th>\n      <td>1</td>\n      <td>2</td>\n      <td>-2</td>\n      <td>5</td>\n      <td>4</td>\n      <td>5</td>\n      <td>11.750000</td>\n      <td>11.859375</td>\n      <td>2.406250</td>\n      <td>12.359375</td>\n      <td>...</td>\n      <td>11.0</td>\n      <td>14.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>21109</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>6</td>\n      <td>4</td>\n      <td>4</td>\n      <td>13.406250</td>\n      <td>15.046875</td>\n      <td>1.562500</td>\n      <td>16.640625</td>\n      <td>...</td>\n      <td>7.0</td>\n      <td>21.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_errados = pd.merge(df_errados, data_clusters, how='inner', left_index=True, right_index=True)\n",
    "datos_errados.rename(columns={'labels gmm_x':'labels gmm'}, inplace=True)\n",
    "datos_errados = datos_errados.drop(['labels gmm_y'], axis=1)\n",
    "datos_errados.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "datos_errados.to_csv('errores clustering.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
